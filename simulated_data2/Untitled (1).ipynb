{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da2d4119-3b15-4286-afdc-cb08edda869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2fa4dca-3f16-4a7c-b8a6-797dc68d468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_tou = pd.read_csv(\"conso_heat_perif_toulouse\")\n",
    "conso_zur = pd.read_csv(\"conso_heat_perif_zurich\")\n",
    "conso_sev = pd.read_csv(\"conso_cool_perif_seville\")\n",
    "occ=pd.read_csv(\"Occupancy_per_hour\",delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "332c1907-36fd-4036-982f-79fdcd1eb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    \"agen\": \"Meteo_Perif_Toulouse_Contemporain/Agen/Simulation_Outputs\",\n",
    "    \"albi\": \"Meteo_Perif_Toulouse_Contemporain/Albi/Simulation_Outputs\",\n",
    "    \"auch\": \"Meteo_Perif_Toulouse_Contemporain/Auch/Simulation_Outputs\",\n",
    "    \"toulouse\": \"Meteo_Perif_Toulouse_Contemporain/Toulouse/Simulation_Outputs\",\n",
    "    \"Birmensdorf\":\"Meteo_Perif_Zurich_Contemporain/Birmensdorf/Simulation_Outputs\",\n",
    "    \"Taenikon\":\"Meteo_Perif_Zurich_Contemporain/Taenikon/Simulation_Outputs\",\n",
    "    \"Zurich_fluntern\":\"Meteo_Perif_Zurich_Contemporain/Zuerich_Fluntern/Simulation_Outputs\",\n",
    "    \"Zurich_kloten\":\"Meteo_Perif_Zurich_Contemporain/Zuerich_kloten/Simulation_Outputs\"\n",
    "}\n",
    "\n",
    "files2 = {\n",
    "    \"Cordoba\": \"Meteo_Perif_Seville_Contemporain/Cordoba/Simulation_Outputs\",\n",
    "    \"Granada\": \"Meteo_Perif_Seville_Contemporain/Granada/Simulation_Outputs\",\n",
    "    \"Malaga\": \"Meteo_Perif_Seville_Contemporain/Malaga/Simulation_Outputs\",\n",
    "    \"Sevilla\": \"Meteo_Perif_Seville_Contemporain/Sevilla/Simulation_Outputs\"   \n",
    "}\n",
    "\n",
    "files3 = {\n",
    "    \"agen\": \"Meteo_Perif_Toulouse_Contemporain/Agen/Meteo_input\",\n",
    "    \"albi\": \"Meteo_Perif_Toulouse_Contemporain/Albi/Meteo_input\",\n",
    "    \"auch\": \"Meteo_Perif_Toulouse_Contemporain/Auch/Meteo_input\",\n",
    "    \"toulouse\": \"Meteo_Perif_Toulouse_Contemporain/Toulouse/Meteo_input\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7839ecc4-e4dd-4512-a8a7-29c84f764200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city, path in files.items():\n",
    "      globals()[f\"Text_{city}\"] = extract_columns(files[city],1)\n",
    "\n",
    "for city2, path2 in files2.items():\n",
    "      globals()[f\"Text_{city2}\"] = extract_columns(files2[city2],1)    \n",
    "\n",
    "for city3, path3 in files3.items():\n",
    "      globals()[f\"hum_{city3}\"] = extract_columns(files3[city3],3)  \n",
    "\n",
    "occupation=extract_columns(\"Occupancy_per_hour\",1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1a895c-825c-414c-bb71-61d88cc15c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_combined_tou = pd.concat([Text_agen, Text_albi,Text_auch,Text_toulouse], axis=0).reset_index(drop=True)\n",
    "Text_combined_zur = pd.concat([Text_Birmensdorf,Text_Taenikon,Text_Zurich_fluntern,Text_Zurich_kloten], axis=0).reset_index(drop=True)\n",
    "Text_combined_sev = pd.concat([Text_Cordoba, Text_Granada,Text_Malaga,Text_Sevilla], axis=0).reset_index(drop=True)\n",
    "Text_combined_tou['clusters'] = conso_tou['clusters']\n",
    "Text_combined_tou['heat_on'] = conso_tou['heat_on']\n",
    "Text_combined_zur['clusters'] = conso_zur['clusters']\n",
    "Text_combined_zur['heat_on'] = conso_zur['heat_on']\n",
    "Text_combined_sev['clusters'] = conso_sev['clusters']\n",
    "Text_combined_sev['cool_on'] = conso_sev['cool_on']\n",
    "Text_combined_tou.columns = Text_combined_tou.columns.astype(str)\n",
    "Text_combined_zur.columns = Text_combined_zur.columns.astype(str)\n",
    "Text_combined_sev.columns = Text_combined_sev.columns.astype(str)\n",
    "\n",
    "\n",
    "Text_occ_agen = pd.concat([Text_agen,occupation],axis=1).reset_index(drop=True)\n",
    "Text_occ_albi = pd.concat([Text_albi,occupation],axis=1).reset_index(drop=True)\n",
    "Text_occ_auch = pd.concat([Text_auch,occupation],axis=1).reset_index(drop=True)\n",
    "Text_occ_toulouse = pd.concat([Text_toulouse,occupation],axis=1).reset_index(drop=True)\n",
    "Text_occ_combined_tou = pd.concat([Text_occ_agen, Text_occ_albi,Text_occ_auch,Text_occ_toulouse], axis=0).reset_index(drop=True)\n",
    "Text_occ_combined_tou['clusters'] = conso_tou['clusters']\n",
    "Text_occ_combined_tou['heat_on'] = conso_tou['heat_on']\n",
    "Text_occ_combined_tou.columns = Text_occ_combined_tou.columns.astype(str)\n",
    "\n",
    "\n",
    "Hum_combined_tou = pd.concat([hum_agen, hum_albi,hum_auch,hum_toulouse], axis=0).reset_index(drop=True)\n",
    "Hum_combined_tou['clusters'] = conso_tou['clusters']\n",
    "Hum_combined_tou['heat_on'] = conso_tou['heat_on']\n",
    "Hum_combined_tou.columns = Hum_combined_tou.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2ac113-f070-4525-ad1f-3dcf96eb381b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>clusters</th>\n",
       "      <th>heat_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.40</td>\n",
       "      <td>10.45</td>\n",
       "      <td>10.40</td>\n",
       "      <td>10.25</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.15</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.10</td>\n",
       "      <td>10.15</td>\n",
       "      <td>10.50</td>\n",
       "      <td>...</td>\n",
       "      <td>13.70</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.60</td>\n",
       "      <td>12.25</td>\n",
       "      <td>11.95</td>\n",
       "      <td>11.60</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.45</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.15</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.45</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.55</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.45</td>\n",
       "      <td>...</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.15</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.45</td>\n",
       "      <td>8.20</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.05</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.35</td>\n",
       "      <td>7.45</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.55</td>\n",
       "      <td>7.60</td>\n",
       "      <td>7.85</td>\n",
       "      <td>...</td>\n",
       "      <td>12.20</td>\n",
       "      <td>11.65</td>\n",
       "      <td>11.10</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.35</td>\n",
       "      <td>8.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.30</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.35</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.95</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.20</td>\n",
       "      <td>8.45</td>\n",
       "      <td>7.75</td>\n",
       "      <td>7.10</td>\n",
       "      <td>6.45</td>\n",
       "      <td>5.80</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.55</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>11.10</td>\n",
       "      <td>9.70</td>\n",
       "      <td>8.65</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.55</td>\n",
       "      <td>7.05</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>-3.25</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>-1.55</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>6.10</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>3.60</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.20</td>\n",
       "      <td>...</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.35</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.25</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>6.25</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.80</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.05</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.55</td>\n",
       "      <td>...</td>\n",
       "      <td>10.45</td>\n",
       "      <td>10.05</td>\n",
       "      <td>9.45</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.20</td>\n",
       "      <td>8.95</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>7.80</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.00</td>\n",
       "      <td>5.25</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0     10.40  10.45  10.40  10.25  10.20  10.15  10.10  10.10  10.15  10.50   \n",
       "1     10.45   9.80   9.15   8.75   8.45   8.10   7.80   7.55   7.40   7.45   \n",
       "2      7.05   7.30   7.30   7.30   7.35   7.45   7.50   7.55   7.60   7.85   \n",
       "3      8.30   8.00   7.35   6.85   6.55   6.25   5.95   5.70   5.60   6.00   \n",
       "4      4.55   4.00   3.45   3.05   2.75   2.45   2.25   2.10   2.00   3.00   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1455  -3.25  -3.25  -3.30  -3.35  -3.45  -3.50  -3.55  -3.60  -3.60  -3.00   \n",
       "1456  -1.55  -1.40  -1.25  -1.15  -1.05  -0.95  -0.85  -0.75  -0.65   0.15   \n",
       "1457   3.60   3.15   2.70   2.40   2.15   1.90   1.70   1.50   1.45   2.20   \n",
       "1458   6.25   6.40   6.55   6.65   6.80   6.95   7.05   7.15   7.20   7.55   \n",
       "1459   7.80   6.95   6.00   5.25   4.70   4.15   3.65   3.20   2.95   3.00   \n",
       "\n",
       "      ...     16     17     18     19     20     21     22     23  clusters  \\\n",
       "0     ...  13.70  13.10  12.60  12.25  11.95  11.60  11.25  10.90       2.0   \n",
       "1     ...   9.60   9.15   8.75   8.45   8.20   7.95   7.65   7.15       2.0   \n",
       "2     ...  12.20  11.65  11.10  10.70  10.30   9.80   9.35   8.75       2.0   \n",
       "3     ...   9.85   9.20   8.45   7.75   7.10   6.45   5.80   5.15       0.0   \n",
       "4     ...  11.10   9.70   8.65   8.10   7.55   7.05   6.50   5.95       2.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...       ...   \n",
       "1455  ...   1.10   0.30  -0.30  -0.55  -0.80  -1.00  -1.20  -1.45       0.0   \n",
       "1456  ...   6.10   5.20   4.60   4.45   4.30   4.15   4.00   3.85       0.0   \n",
       "1457  ...   7.95   7.00   6.35   6.30   6.30   6.25   6.20   6.20       2.0   \n",
       "1458  ...  10.45  10.05   9.45   9.20   9.20   8.95   8.60   8.30       2.0   \n",
       "1459  ...   3.00   2.55   2.25   1.95   1.55   1.15   0.70   0.30       0.0   \n",
       "\n",
       "      heat_on  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "1455        1  \n",
       "1456        1  \n",
       "1457        1  \n",
       "1458        1  \n",
       "1459        1  \n",
       "\n",
       "[1460 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_combined_tou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1a54797-5554-4a3a-b777-0daf084e1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "X=Text_combined_tou.drop(columns=[\"clusters\"])\n",
    "y=Text_combined_tou[\"clusters\"]\n",
    "X_scaled=standardize_data(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41927aa8-bfe4-4a6d-8c8b-7b48da9cfbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1))) / (tf.reduce_sum(tf.round(tf.clip_by_value(y_pred, 0, 1))) + tf.keras.backend.epsilon())\n",
    "    recall = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1))) / (tf.reduce_sum(tf.round(tf.clip_by_value(y_true, 0, 1))) + tf.keras.backend.epsilon())\n",
    "    return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b04bb98-325f-4d8a-b00e-4db82f57006c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,260</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 │           \u001b[38;5;34m3,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)                  │           \u001b[38;5;34m7,260\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m244\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,624</span> (41.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,624\u001b[0m (41.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,624</span> (41.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,624\u001b[0m (41.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=120, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=60, activation='relu'))\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be76e886-cec7-4da0-8174-ebcd15dd1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3119731a-9932-4eb7-ba8c-e9fc15ad0f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6611 - f1_score: 0.4771 - loss: 0.8903 - val_accuracy: 0.8493 - val_f1_score: 0.6682 - val_loss: 0.5449\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8144 - f1_score: 0.7094 - loss: 0.5075 - val_accuracy: 0.8596 - val_f1_score: 0.8185 - val_loss: 0.4086\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8428 - f1_score: 0.8204 - loss: 0.3675 - val_accuracy: 0.8767 - val_f1_score: 0.8281 - val_loss: 0.3434\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8638 - f1_score: 0.8455 - loss: 0.3256 - val_accuracy: 0.8596 - val_f1_score: 0.8812 - val_loss: 0.3037\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8520 - f1_score: 0.8532 - loss: 0.3012 - val_accuracy: 0.8459 - val_f1_score: 0.8553 - val_loss: 0.3203\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8506 - f1_score: 0.8536 - loss: 0.2889 - val_accuracy: 0.8767 - val_f1_score: 0.8766 - val_loss: 0.2785\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8748 - f1_score: 0.8671 - loss: 0.2628 - val_accuracy: 0.8767 - val_f1_score: 0.8807 - val_loss: 0.2714\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8725 - f1_score: 0.8673 - loss: 0.2690 - val_accuracy: 0.8322 - val_f1_score: 0.8346 - val_loss: 0.3041\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8555 - f1_score: 0.8573 - loss: 0.2795 - val_accuracy: 0.8493 - val_f1_score: 0.8693 - val_loss: 0.2980\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8637 - f1_score: 0.8637 - loss: 0.2758 - val_accuracy: 0.8493 - val_f1_score: 0.8671 - val_loss: 0.2894\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8795 - f1_score: 0.8726 - loss: 0.2484 - val_accuracy: 0.8767 - val_f1_score: 0.8881 - val_loss: 0.2624\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8936 - f1_score: 0.8901 - loss: 0.2441 - val_accuracy: 0.8699 - val_f1_score: 0.8876 - val_loss: 0.2546\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8688 - f1_score: 0.8630 - loss: 0.2553 - val_accuracy: 0.8699 - val_f1_score: 0.8804 - val_loss: 0.2656\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8651 - f1_score: 0.8626 - loss: 0.2749 - val_accuracy: 0.8733 - val_f1_score: 0.8772 - val_loss: 0.2632\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8648 - f1_score: 0.8661 - loss: 0.2543 - val_accuracy: 0.8767 - val_f1_score: 0.8833 - val_loss: 0.2538\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8861 - f1_score: 0.8870 - loss: 0.2331 - val_accuracy: 0.8493 - val_f1_score: 0.8668 - val_loss: 0.2781\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8755 - f1_score: 0.8749 - loss: 0.2464 - val_accuracy: 0.8596 - val_f1_score: 0.8722 - val_loss: 0.2668\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8784 - f1_score: 0.8787 - loss: 0.2636 - val_accuracy: 0.8767 - val_f1_score: 0.8840 - val_loss: 0.2485\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8682 - f1_score: 0.8704 - loss: 0.2577 - val_accuracy: 0.8425 - val_f1_score: 0.8575 - val_loss: 0.2904\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8697 - f1_score: 0.8751 - loss: 0.2475 - val_accuracy: 0.8699 - val_f1_score: 0.8779 - val_loss: 0.2562\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8911 - f1_score: 0.8861 - loss: 0.2332 - val_accuracy: 0.8904 - val_f1_score: 0.8965 - val_loss: 0.2546\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8855 - f1_score: 0.8862 - loss: 0.2359 - val_accuracy: 0.8801 - val_f1_score: 0.8899 - val_loss: 0.2424\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8879 - f1_score: 0.8812 - loss: 0.2402 - val_accuracy: 0.8767 - val_f1_score: 0.8868 - val_loss: 0.2480\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8986 - f1_score: 0.8939 - loss: 0.2229 - val_accuracy: 0.8801 - val_f1_score: 0.8903 - val_loss: 0.2453\n",
      "Epoch 25/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8990 - f1_score: 0.8940 - loss: 0.2332 - val_accuracy: 0.8699 - val_f1_score: 0.8872 - val_loss: 0.2539\n",
      "Epoch 26/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8847 - f1_score: 0.8884 - loss: 0.2364 - val_accuracy: 0.8767 - val_f1_score: 0.8882 - val_loss: 0.2495\n",
      "Epoch 27/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8876 - f1_score: 0.8875 - loss: 0.2219 - val_accuracy: 0.8733 - val_f1_score: 0.8831 - val_loss: 0.2489\n",
      "Epoch 28/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8872 - f1_score: 0.8855 - loss: 0.2410 - val_accuracy: 0.8664 - val_f1_score: 0.8781 - val_loss: 0.2525\n",
      "Epoch 29/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8689 - f1_score: 0.8694 - loss: 0.2688 - val_accuracy: 0.8767 - val_f1_score: 0.8831 - val_loss: 0.2509\n",
      "Epoch 30/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8631 - f1_score: 0.8700 - loss: 0.2558 - val_accuracy: 0.8390 - val_f1_score: 0.8566 - val_loss: 0.2847\n",
      "Epoch 31/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8639 - f1_score: 0.8632 - loss: 0.2774 - val_accuracy: 0.8699 - val_f1_score: 0.8825 - val_loss: 0.2542\n",
      "Epoch 32/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8885 - f1_score: 0.8845 - loss: 0.2271 - val_accuracy: 0.8699 - val_f1_score: 0.8768 - val_loss: 0.2561\n",
      "Epoch 33/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8696 - f1_score: 0.8705 - loss: 0.2602 - val_accuracy: 0.8664 - val_f1_score: 0.8786 - val_loss: 0.2569\n",
      "Epoch 34/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8789 - f1_score: 0.8781 - loss: 0.2445 - val_accuracy: 0.8767 - val_f1_score: 0.8901 - val_loss: 0.2521\n",
      "Epoch 35/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8769 - f1_score: 0.8793 - loss: 0.2460 - val_accuracy: 0.8664 - val_f1_score: 0.8817 - val_loss: 0.2478\n",
      "Epoch 36/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8908 - f1_score: 0.8922 - loss: 0.2295 - val_accuracy: 0.8630 - val_f1_score: 0.8724 - val_loss: 0.2526\n",
      "Epoch 37/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8928 - f1_score: 0.8920 - loss: 0.2168 - val_accuracy: 0.8699 - val_f1_score: 0.8786 - val_loss: 0.2502\n",
      "Epoch 38/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8872 - f1_score: 0.8926 - loss: 0.2351 - val_accuracy: 0.8801 - val_f1_score: 0.8871 - val_loss: 0.2611\n",
      "Epoch 39/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8570 - f1_score: 0.8606 - loss: 0.2653 - val_accuracy: 0.8699 - val_f1_score: 0.8839 - val_loss: 0.2614\n",
      "Epoch 40/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8935 - f1_score: 0.8949 - loss: 0.2333 - val_accuracy: 0.8767 - val_f1_score: 0.8858 - val_loss: 0.2496\n",
      "Epoch 41/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9044 - f1_score: 0.9039 - loss: 0.2155 - val_accuracy: 0.8699 - val_f1_score: 0.8810 - val_loss: 0.2449\n",
      "Epoch 42/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9049 - f1_score: 0.9029 - loss: 0.2217 - val_accuracy: 0.8664 - val_f1_score: 0.8730 - val_loss: 0.2647\n",
      "Epoch 43/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8924 - f1_score: 0.8894 - loss: 0.2359 - val_accuracy: 0.8664 - val_f1_score: 0.8796 - val_loss: 0.2492\n",
      "Epoch 44/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8871 - f1_score: 0.8817 - loss: 0.2386 - val_accuracy: 0.8527 - val_f1_score: 0.8701 - val_loss: 0.2538\n",
      "Epoch 45/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8857 - f1_score: 0.8844 - loss: 0.2310 - val_accuracy: 0.8562 - val_f1_score: 0.8710 - val_loss: 0.2607\n",
      "Epoch 46/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8904 - f1_score: 0.8904 - loss: 0.2338 - val_accuracy: 0.8630 - val_f1_score: 0.8695 - val_loss: 0.2558\n",
      "Epoch 47/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8755 - f1_score: 0.8819 - loss: 0.2516 - val_accuracy: 0.8630 - val_f1_score: 0.8706 - val_loss: 0.2646\n",
      "Epoch 48/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8978 - f1_score: 0.8973 - loss: 0.2420 - val_accuracy: 0.8767 - val_f1_score: 0.8813 - val_loss: 0.2549\n",
      "Epoch 49/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8875 - f1_score: 0.8881 - loss: 0.2264 - val_accuracy: 0.8322 - val_f1_score: 0.8468 - val_loss: 0.2848\n",
      "Epoch 50/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8885 - f1_score: 0.8866 - loss: 0.2282 - val_accuracy: 0.8767 - val_f1_score: 0.8855 - val_loss: 0.2476\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79d739e4-d1c7-476f-89f7-26897736fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPooling1D, Dropout, BatchNormalization, InputLayer\n",
    "\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8648a82-ab9f-405e-b403-83d18adaffae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toubia\\anaconda3\\envs\\notebook\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5623 - f1_score: 0.5379 - loss: 1.1299 - val_accuracy: 0.6575 - val_f1_score: 0.0000e+00 - val_loss: 1.1852\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7504 - f1_score: 0.7467 - loss: 0.5714 - val_accuracy: 0.3767 - val_f1_score: 0.0000e+00 - val_loss: 1.1845\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7372 - f1_score: 0.7213 - loss: 0.5673 - val_accuracy: 0.3048 - val_f1_score: 0.0000e+00 - val_loss: 1.1782\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7379 - f1_score: 0.7183 - loss: 0.5789 - val_accuracy: 0.3973 - val_f1_score: 0.0360 - val_loss: 1.1095\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7471 - f1_score: 0.7415 - loss: 0.5655 - val_accuracy: 0.5993 - val_f1_score: 0.0627 - val_loss: 1.0924\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7399 - f1_score: 0.7244 - loss: 0.6101 - val_accuracy: 0.3973 - val_f1_score: 0.1353 - val_loss: 1.0377\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7558 - f1_score: 0.7324 - loss: 0.5468 - val_accuracy: 0.4795 - val_f1_score: 0.3362 - val_loss: 0.9462\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7669 - f1_score: 0.7475 - loss: 0.5267 - val_accuracy: 0.7363 - val_f1_score: 0.5172 - val_loss: 0.8552\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7761 - f1_score: 0.7745 - loss: 0.4693 - val_accuracy: 0.7021 - val_f1_score: 0.6890 - val_loss: 0.7518\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7529 - f1_score: 0.7486 - loss: 0.5311 - val_accuracy: 0.6918 - val_f1_score: 0.6912 - val_loss: 0.6992\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7628 - f1_score: 0.7595 - loss: 0.5287 - val_accuracy: 0.7397 - val_f1_score: 0.6889 - val_loss: 0.6505\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7504 - f1_score: 0.7316 - loss: 0.5147 - val_accuracy: 0.7329 - val_f1_score: 0.7111 - val_loss: 0.6116\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7650 - f1_score: 0.7562 - loss: 0.5135 - val_accuracy: 0.7260 - val_f1_score: 0.6803 - val_loss: 0.5920\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7365 - f1_score: 0.7228 - loss: 0.5333 - val_accuracy: 0.7808 - val_f1_score: 0.7650 - val_loss: 0.5221\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7471 - f1_score: 0.7447 - loss: 0.5034 - val_accuracy: 0.7295 - val_f1_score: 0.7302 - val_loss: 0.5379\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7606 - f1_score: 0.7440 - loss: 0.5130 - val_accuracy: 0.7397 - val_f1_score: 0.7219 - val_loss: 0.5329\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7695 - f1_score: 0.7549 - loss: 0.5030 - val_accuracy: 0.8048 - val_f1_score: 0.7709 - val_loss: 0.4777\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7708 - f1_score: 0.7503 - loss: 0.4908 - val_accuracy: 0.7945 - val_f1_score: 0.8037 - val_loss: 0.5005\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7662 - f1_score: 0.7558 - loss: 0.5032 - val_accuracy: 0.7808 - val_f1_score: 0.7789 - val_loss: 0.4734\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7705 - f1_score: 0.7567 - loss: 0.5052 - val_accuracy: 0.7774 - val_f1_score: 0.7644 - val_loss: 0.5019\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7737 - f1_score: 0.7499 - loss: 0.5037 - val_accuracy: 0.7363 - val_f1_score: 0.7421 - val_loss: 0.4959\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7581 - f1_score: 0.7621 - loss: 0.4892 - val_accuracy: 0.8082 - val_f1_score: 0.7997 - val_loss: 0.4563\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7935 - f1_score: 0.7866 - loss: 0.4710 - val_accuracy: 0.7740 - val_f1_score: 0.7841 - val_loss: 0.4799\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7637 - f1_score: 0.7631 - loss: 0.5040 - val_accuracy: 0.7534 - val_f1_score: 0.7403 - val_loss: 0.4732\n",
      "Epoch 25/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7829 - f1_score: 0.7772 - loss: 0.4782 - val_accuracy: 0.7808 - val_f1_score: 0.8120 - val_loss: 0.4561\n",
      "Epoch 26/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7554 - f1_score: 0.7409 - loss: 0.5492 - val_accuracy: 0.8116 - val_f1_score: 0.8149 - val_loss: 0.4513\n",
      "Epoch 27/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7777 - f1_score: 0.7724 - loss: 0.4763 - val_accuracy: 0.8014 - val_f1_score: 0.7929 - val_loss: 0.4492\n",
      "Epoch 28/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7893 - f1_score: 0.7858 - loss: 0.4580 - val_accuracy: 0.7637 - val_f1_score: 0.7472 - val_loss: 0.4650\n",
      "Epoch 29/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7642 - f1_score: 0.7682 - loss: 0.4932 - val_accuracy: 0.8116 - val_f1_score: 0.7873 - val_loss: 0.4292\n",
      "Epoch 30/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7816 - f1_score: 0.7747 - loss: 0.4782 - val_accuracy: 0.8048 - val_f1_score: 0.8271 - val_loss: 0.4339\n",
      "Epoch 31/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7779 - f1_score: 0.7666 - loss: 0.4794 - val_accuracy: 0.7842 - val_f1_score: 0.8000 - val_loss: 0.4461\n",
      "Epoch 32/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7849 - f1_score: 0.7734 - loss: 0.4628 - val_accuracy: 0.7603 - val_f1_score: 0.7830 - val_loss: 0.4650\n",
      "Epoch 33/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7435 - f1_score: 0.7516 - loss: 0.5155 - val_accuracy: 0.8253 - val_f1_score: 0.8245 - val_loss: 0.4297\n",
      "Epoch 34/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7869 - f1_score: 0.7770 - loss: 0.4628 - val_accuracy: 0.8185 - val_f1_score: 0.8242 - val_loss: 0.4311\n",
      "Epoch 35/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7971 - f1_score: 0.7820 - loss: 0.4554 - val_accuracy: 0.8219 - val_f1_score: 0.8505 - val_loss: 0.4277\n",
      "Epoch 36/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7641 - f1_score: 0.7557 - loss: 0.4867 - val_accuracy: 0.8493 - val_f1_score: 0.8448 - val_loss: 0.4191\n",
      "Epoch 37/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7773 - f1_score: 0.7716 - loss: 0.4735 - val_accuracy: 0.8116 - val_f1_score: 0.8262 - val_loss: 0.4264\n",
      "Epoch 38/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8101 - f1_score: 0.8119 - loss: 0.4216 - val_accuracy: 0.8014 - val_f1_score: 0.8145 - val_loss: 0.4324\n",
      "Epoch 39/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8065 - f1_score: 0.7851 - loss: 0.4337 - val_accuracy: 0.8048 - val_f1_score: 0.8139 - val_loss: 0.4307\n",
      "Epoch 40/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7859 - f1_score: 0.7749 - loss: 0.4928 - val_accuracy: 0.8185 - val_f1_score: 0.8354 - val_loss: 0.4146\n",
      "Epoch 41/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7869 - f1_score: 0.7856 - loss: 0.4548 - val_accuracy: 0.8356 - val_f1_score: 0.8214 - val_loss: 0.4274\n",
      "Epoch 42/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7732 - f1_score: 0.7789 - loss: 0.4649 - val_accuracy: 0.8253 - val_f1_score: 0.8302 - val_loss: 0.4435\n",
      "Epoch 43/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7888 - f1_score: 0.7879 - loss: 0.4587 - val_accuracy: 0.7568 - val_f1_score: 0.7547 - val_loss: 0.4640\n",
      "Epoch 44/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7880 - f1_score: 0.7851 - loss: 0.4316 - val_accuracy: 0.8185 - val_f1_score: 0.8241 - val_loss: 0.4245\n",
      "Epoch 45/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8070 - f1_score: 0.7929 - loss: 0.4405 - val_accuracy: 0.7979 - val_f1_score: 0.8147 - val_loss: 0.4318\n",
      "Epoch 46/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7964 - f1_score: 0.7869 - loss: 0.4472 - val_accuracy: 0.7979 - val_f1_score: 0.7937 - val_loss: 0.4449\n",
      "Epoch 47/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7965 - f1_score: 0.7886 - loss: 0.4455 - val_accuracy: 0.8219 - val_f1_score: 0.7893 - val_loss: 0.4246\n",
      "Epoch 48/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8098 - f1_score: 0.8024 - loss: 0.4252 - val_accuracy: 0.8562 - val_f1_score: 0.8604 - val_loss: 0.4162\n",
      "Epoch 49/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7834 - f1_score: 0.7867 - loss: 0.4534 - val_accuracy: 0.8082 - val_f1_score: 0.7929 - val_loss: 0.4147\n",
      "Epoch 50/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7868 - f1_score: 0.7885 - loss: 0.4342 - val_accuracy: 0.8082 - val_f1_score: 0.8052 - val_loss: 0.4164\n"
     ]
    }
   ],
   "source": [
    "model_cnn = Sequential([\n",
    "    InputLayer(input_shape=(24, 1)), \n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "model_cnn.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy',f1_score])\n",
    "\n",
    "\n",
    "history_cnn = model_cnn.fit(X_train_cnn, y_train, \n",
    "                            validation_data=(X_test_cnn, y_test), \n",
    "                            epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0befd-0ca9-4a23-a5d0-de4e4bed1c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
